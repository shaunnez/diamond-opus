name: Infrastructure

on:
  push:
    branches:
      - main
    paths:
      - 'infrastructure/terraform/**'
  pull_request:
    branches:
      - main
    paths:
      - 'infrastructure/terraform/**'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - prod
      action:
        description: 'Terraform action'
        required: true
        default: 'plan'
        type: choice
        options:
          - plan
          - apply

env:
  ARM_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
  ARM_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
  ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
  ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
  TF_VERSION: '1.6.0'

jobs:
  # Plan for staging on PR
  plan-staging:
    name: Plan Staging
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    environment: staging
    defaults:
      run:
        working-directory: infrastructure/terraform/environments/staging

    env:
      # Terraform variables from GitHub Secrets
      TF_VAR_subscription_id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
      TF_VAR_database_host: ${{ secrets.TF_VAR_DATABASE_HOST }}
      TF_VAR_database_username: ${{ secrets.TF_VAR_DATABASE_USERNAME }}
      TF_VAR_database_password: ${{ secrets.TF_VAR_DATABASE_PASSWORD }}
      TF_VAR_nivoda_endpoint: ${{ secrets.TF_VAR_NIVODA_ENDPOINT }}
      TF_VAR_nivoda_username: ${{ secrets.TF_VAR_NIVODA_USERNAME }}
      TF_VAR_nivoda_password: ${{ secrets.TF_VAR_NIVODA_PASSWORD }}
      TF_VAR_hmac_secrets: ${{ secrets.TF_VAR_HMAC_SECRETS }}
      TF_VAR_resend_api_key: ${{ secrets.TF_VAR_RESEND_API_KEY }}
      TF_VAR_alert_email_to: ${{ secrets.TF_VAR_ALERT_EMAIL_TO }}
      TF_VAR_alert_email_from: ${{ secrets.TF_VAR_ALERT_EMAIL_FROM }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Terraform Init
        run: terraform init

      - name: Terraform Format Check
        run: terraform fmt -check -recursive

      - name: Terraform Validate
        run: terraform validate

      - name: Terraform Plan
        run: terraform plan -no-color
        continue-on-error: true

  # Plan for production on PR
  plan-prod:
    name: Plan Production
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    environment: production
    defaults:
      run:
        working-directory: infrastructure/terraform/environments/prod

    env:
      # Terraform variables from GitHub Secrets
      TF_VAR_subscription_id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
      TF_VAR_database_host: ${{ secrets.TF_VAR_DATABASE_HOST }}
      TF_VAR_database_username: ${{ secrets.TF_VAR_DATABASE_USERNAME }}
      TF_VAR_database_password: ${{ secrets.TF_VAR_DATABASE_PASSWORD }}
      TF_VAR_nivoda_endpoint: ${{ secrets.TF_VAR_NIVODA_ENDPOINT }}
      TF_VAR_nivoda_username: ${{ secrets.TF_VAR_NIVODA_USERNAME }}
      TF_VAR_nivoda_password: ${{ secrets.TF_VAR_NIVODA_PASSWORD }}
      TF_VAR_hmac_secrets: ${{ secrets.TF_VAR_HMAC_SECRETS }}
      TF_VAR_resend_api_key: ${{ secrets.TF_VAR_RESEND_API_KEY }}
      TF_VAR_alert_email_to: ${{ secrets.TF_VAR_ALERT_EMAIL_TO }}
      TF_VAR_alert_email_from: ${{ secrets.TF_VAR_ALERT_EMAIL_FROM }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Terraform Init
        run: terraform init

      - name: Terraform Plan
        run: terraform plan -no-color
        continue-on-error: true

  # Deploy on manual trigger or push to main
  deploy:
    name: Deploy ${{ github.event.inputs.environment || 'staging' }}
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' || (github.event_name == 'push' && github.ref == 'refs/heads/main')
    environment: ${{ github.event.inputs.environment || 'staging' }}

    env:
      TF_ENV: ${{ github.event.inputs.environment || 'staging' }}
      # Terraform variables from GitHub Secrets (environment-specific)
      TF_VAR_subscription_id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
      TF_VAR_database_host: ${{ secrets.TF_VAR_DATABASE_HOST }}
      TF_VAR_database_username: ${{ secrets.TF_VAR_DATABASE_USERNAME }}
      TF_VAR_database_password: ${{ secrets.TF_VAR_DATABASE_PASSWORD }}
      TF_VAR_nivoda_endpoint: ${{ secrets.TF_VAR_NIVODA_ENDPOINT }}
      TF_VAR_nivoda_username: ${{ secrets.TF_VAR_NIVODA_USERNAME }}
      TF_VAR_nivoda_password: ${{ secrets.TF_VAR_NIVODA_PASSWORD }}
      TF_VAR_hmac_secrets: ${{ secrets.TF_VAR_HMAC_SECRETS }}
      TF_VAR_resend_api_key: ${{ secrets.TF_VAR_RESEND_API_KEY }}
      TF_VAR_alert_email_to: ${{ secrets.TF_VAR_ALERT_EMAIL_TO }}
      TF_VAR_alert_email_from: ${{ secrets.TF_VAR_ALERT_EMAIL_FROM }}

    defaults:
      run:
        working-directory: infrastructure/terraform/environments/${{ github.event.inputs.environment || 'staging' }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Azure Login
        uses: Azure/login@v2.3.0
        with:
          creds: '{"clientId":"${{ secrets.AZURE_CLIENT_ID }}","clientSecret":"${{ secrets.AZURE_CLIENT_SECRET }}","tenantId":"${{ secrets.AZURE_TENANT_ID }}","subscriptionId":"${{ secrets.AZURE_SUBSCRIPTION_ID }}"}'

      - name: Get current image tag from deployed container
        id: current_image
        run: |
          # Determine resource group based on environment
          if [ "$TF_ENV" = "prod" ]; then
            RG="diamond-prod-rg"
            APP_PREFIX="diamond-prod"
          else
            RG="diamond-staging-rg"
            APP_PREFIX="diamond-staging"
          fi

          # Try to get current image tag from the API container (representative of deployed version)
          CURRENT_IMAGE=$(az containerapp show \
            --name "${APP_PREFIX}-api" \
            --resource-group "$RG" \
            --query "properties.template.containers[0].image" \
            -o tsv 2>/dev/null || echo "")

          if [ -n "$CURRENT_IMAGE" ]; then
            # Extract tag from image (e.g., "acr.azurecr.io/diamond-api:abc1234" -> "abc1234")
            IMAGE_TAG="${CURRENT_IMAGE##*:}"
            echo "Found current image tag: $IMAGE_TAG"
            echo "tag=$IMAGE_TAG" >> $GITHUB_OUTPUT
          else
            # Fallback to environment default if no container exists yet
            if [ "$TF_ENV" = "prod" ]; then
              echo "tag=latest" >> $GITHUB_OUTPUT
            else
              echo "tag=staging" >> $GITHUB_OUTPUT
            fi
            echo "No existing container found, using default tag"
          fi

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}

      - name: Terraform Init
        run: terraform init

      - name: Diagnose Terraform State vs Azure (Pre-Plan)
        run: |
          echo "=== TERRAFORM STATE DIAGNOSTICS ==="

          # Determine resource group
          if [ "$TF_ENV" = "prod" ]; then
            RG="diamond-prod-rg"
            APP_PREFIX="diamond-prod"
          else
            RG="diamond-staging-rg"
            APP_PREFIX="diamond-staging"
          fi

          echo ""
          echo "### Terraform State - Consolidator Scale Rules ###"
          terraform state show 'module.container_apps.azurerm_container_app.consolidator' 2>/dev/null | grep -A 20 "custom_scale_rule" || echo "No scale rules in Terraform state or resource not found"

          echo ""
          echo "### Azure Reality - Consolidator Scale Rules ###"
          az containerapp show \
            --name "${APP_PREFIX}-consolidator" \
            --resource-group "$RG" \
            --query "properties.template.scale" \
            -o json 2>/dev/null || echo "Consolidator not found in Azure"

          echo ""
          echo "### Checking for State Drift ###"
          # If Terraform has scale rules but Azure doesn't, we need to taint
          TF_HAS_SCALE=$(terraform state show 'module.container_apps.azurerm_container_app.consolidator' 2>/dev/null | grep -c "custom_scale_rule" || echo "0")
          AZURE_SCALE=$(az containerapp show --name "${APP_PREFIX}-consolidator" --resource-group "$RG" --query "properties.template.scale.rules" -o tsv 2>/dev/null || echo "")

          echo "Terraform has scale rules: $TF_HAS_SCALE lines"
          echo "Azure scale rules: ${AZURE_SCALE:-none}"

          if [ "$TF_HAS_SCALE" -gt "0" ] && [ -z "$AZURE_SCALE" ]; then
            echo ""
            echo "STATE DRIFT DETECTED: Terraform thinks scale rules exist but Azure doesn't have them"
            echo "Will taint the consolidator resource to force recreation..."
            terraform taint 'module.container_apps.azurerm_container_app.consolidator' || echo "Taint failed - resource may not exist"
          fi

      - name: Terraform Plan
        id: plan
        env:
          TF_VAR_image_tag: ${{ steps.current_image.outputs.tag }}
        run: terraform plan -out=tfplan -no-color

      - name: Terraform Apply
        if: github.event.inputs.action == 'apply' || github.event_name == 'push'
        run: terraform apply -auto-approve tfplan

      - name: Verify Consolidator Scale Rules (Post-Apply)
        if: github.event.inputs.action == 'apply' || github.event_name == 'push'
        run: |
          echo "=== POST-APPLY VERIFICATION ==="

          if [ "$TF_ENV" = "prod" ]; then
            RG="diamond-prod-rg"
            APP_PREFIX="diamond-prod"
          else
            RG="diamond-staging-rg"
            APP_PREFIX="diamond-staging"
          fi

          echo "### Consolidator Configuration After Apply ###"
          az containerapp show \
            --name "${APP_PREFIX}-consolidator" \
            --resource-group "$RG" \
            --query "{
              name: name,
              minReplicas: properties.template.scale.minReplicas,
              maxReplicas: properties.template.scale.maxReplicas,
              scaleRules: properties.template.scale.rules,
              cpu: properties.template.containers[0].resources.cpu,
              memory: properties.template.containers[0].resources.memory
            }" \
            -o json

          # Verify scale rule exists
          SCALE_RULES=$(az containerapp show --name "${APP_PREFIX}-consolidator" --resource-group "$RG" --query "properties.template.scale.rules" -o json)
          if echo "$SCALE_RULES" | grep -q "servicebus"; then
            echo "Service Bus scale rule is configured correctly"
          else
            echo "WARNING: Service Bus scale rule NOT found after apply!"
            echo "Scale rules found: $SCALE_RULES"
          fi
