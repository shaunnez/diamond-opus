---
phase: 01-rate-limiting-separation
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - infrastructure/terraform/modules/container-apps/main.tf
  - infrastructure/terraform/modules/container-apps/variables.tf
  - infrastructure/terraform/modules/container-apps/outputs.tf
autonomous: true
requirements: [RATE-01, RATE-05]

must_haves:
  truths:
    - "Ingestion proxy deploys as single-replica Container App"
    - "Proxy has internal ingress only (not public)"
    - "Health probes configured (startup, liveness, readiness)"
    - "Terraform plan succeeds without errors"
  artifacts:
    - path: "infrastructure/terraform/modules/container-apps/main.tf"
      provides: "azurerm_container_app.ingestion_proxy resource"
      contains: "resource \"azurerm_container_app\" \"ingestion_proxy\""
    - path: "infrastructure/terraform/modules/container-apps/variables.tf"
      provides: "ingestion_proxy configuration variables"
      contains: "ingestion_proxy"
    - path: "infrastructure/terraform/modules/container-apps/outputs.tf"
      provides: "ingestion_proxy FQDN output"
      contains: "ingestion_proxy_fqdn"
  key_links:
    - from: "azurerm_container_app.ingestion_proxy"
      to: "azurerm_container_app_environment.main"
      via: "container_app_environment_id reference"
      pattern: "container_app_environment_id.*azurerm_container_app_environment\\.main"
    - from: "azurerm_container_app.ingestion_proxy.ingress"
      to: "external_enabled = false"
      via: "internal ingress configuration"
      pattern: "external_enabled\\s*=\\s*false"
    - from: "azurerm_container_app.ingestion_proxy.template"
      to: "min_replicas = 1, max_replicas = 1"
      via: "single replica enforcement"
      pattern: "min_replicas\\s*=\\s*1.*max_replicas\\s*=\\s*1"
---

<objective>
Add Terraform infrastructure for dedicated ingestion proxy Container App with single-replica enforcement, internal ingress, and health probes.

Purpose: Deploy rate-limiting bottleneck as isolated Container App that scheduler/worker can route through without affecting customer API scaling.

Output: Terraform resources for ingestion-proxy Container App with health checks, internal FQDN output for service discovery.
</objective>

<execution_context>
@/Users/shaunnesbitt/.claude/get-shit-done/workflows/execute-plan.md
@/Users/shaunnesbitt/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-rate-limiting-separation/01-RESEARCH.md

# Existing Terraform patterns
@infrastructure/terraform/modules/container-apps/main.tf
@infrastructure/terraform/modules/container-apps/variables.tf
@infrastructure/terraform/modules/container-apps/outputs.tf
</context>

<tasks>

<task type="auto">
  <name>Add ingestion-proxy Container App resource</name>
  <files>
infrastructure/terraform/modules/container-apps/main.tf
  </files>
  <action>
Add new Container App resource to `main.tf` after the API Container App resource:

**Resource: azurerm_container_app.ingestion_proxy**

Configuration:
- name: `"${var.app_name_prefix}-ingestion-proxy"`
- container_app_environment_id: reference to main environment
- resource_group_name: var.resource_group_name
- revision_mode: "Single"

**template block:**
- min_replicas: 1 (critical: prevents scale to zero)
- max_replicas: 1 (critical: enforces single replica for global rate limit)

**container block:**
- name: "ingestion-proxy"
- image: `"${var.container_registry_login_server}/diamond-ingestion-proxy:${var.image_tag}"`
- cpu: 0.5 (proxy workload is lightweight)
- memory: "1Gi"

**Environment variables:**
- SERVICE_NAME: "ingestion-proxy"
- PORT: "3000"
- DATABASE_HOST, DATABASE_PORT, DATABASE_NAME, DATABASE_USERNAME, DATABASE_PASSWORD (secrets, same as API)
- NIVODA_ENDPOINT (secret)
- NIVODA_USERNAME, NIVODA_PASSWORD (secrets)
- INTERNAL_SERVICE_TOKEN (secret)
- NIVODA_PROXY_RATE_LIMIT: var.nivoda_proxy_rate_limit (default 25)
- NIVODA_PROXY_RATE_LIMIT_MAX_WAIT_MS: var.nivoda_proxy_rate_limit_max_wait_ms (default 60000)
- NIVODA_PROXY_TIMEOUT_MS: var.nivoda_proxy_timeout_ms (default 60000)

**Health probes (per RESEARCH.md Pattern 4):**

startup_probe:
- transport: "TCP"
- port: 3000
- initial_delay: 1
- period_seconds: 1
- timeout: 3
- failure_threshold: 30

liveness_probe:
- transport: "TCP"
- port: 3000
- period_seconds: 10
- timeout: 1
- failure_threshold: 10

readiness_probe:
- transport: "TCP"
- port: 3000
- period_seconds: 5
- timeout: 5
- failure_threshold: 3

**ingress block:**
- external_enabled: false (CRITICAL: internal only)
- target_port: 3000
- transport: "http"
- traffic_weight: percentage 100, latest_revision true

**registry block:** Same pattern as API (reference container_registry vars, password_secret_name)

**secrets:** Add secrets for nivoda-endpoint, nivoda-username, nivoda-password, internal-service-token (same pattern as API Container App)

Follow existing API Container App structure but with single-replica enforcement and internal ingress.
  </action>
  <verify>
```bash
grep -A 5 'resource "azurerm_container_app" "ingestion_proxy"' infrastructure/terraform/modules/container-apps/main.tf
grep -q "min_replicas = 1" infrastructure/terraform/modules/container-apps/main.tf
grep -q "max_replicas = 1" infrastructure/terraform/modules/container-apps/main.tf
grep -q "external_enabled = false" infrastructure/terraform/modules/container-apps/main.tf
terraform -chdir=infrastructure/terraform/modules/container-apps init
terraform -chdir=infrastructure/terraform/modules/container-apps validate
```
  </verify>
  <done>
- Resource azurerm_container_app.ingestion_proxy exists
- min_replicas and max_replicas both set to 1
- external_enabled set to false
- Health probes configured (startup, liveness, readiness)
- Terraform validates successfully
  </done>
</task>

<task type="auto">
  <name>Add ingestion-proxy variables and outputs</name>
  <files>
infrastructure/terraform/modules/container-apps/variables.tf
infrastructure/terraform/modules/container-apps/outputs.tf
  </files>
  <action>
**1. Add variables to variables.tf:**

Add after existing proxy-related variables:

```hcl
variable "nivoda_proxy_rate_limit" {
  description = "Max requests per second to Nivoda (global limit enforced by single-replica proxy)"
  type        = number
  default     = 25
}

variable "nivoda_proxy_rate_limit_max_wait_ms" {
  description = "Max time queued request waits before 429 response"
  type        = number
  default     = 60000
}

variable "nivoda_proxy_timeout_ms" {
  description = "Timeout for upstream Nivoda requests"
  type        = number
  default     = 60000
}
```

**2. Add output to outputs.tf:**

Add new output for ingestion proxy FQDN (needed for scheduler/worker routing):

```hcl
output "ingestion_proxy_fqdn" {
  description = "Internal FQDN for ingestion proxy (scheduler/worker routing)"
  value       = azurerm_container_app.ingestion_proxy.ingress[0].fqdn
  sensitive   = false
}
```

This output will be referenced in scheduler/worker Container App env vars.
  </action>
  <verify>
```bash
grep -q "variable \"nivoda_proxy_rate_limit\"" infrastructure/terraform/modules/container-apps/variables.tf
grep -q "output \"ingestion_proxy_fqdn\"" infrastructure/terraform/modules/container-apps/outputs.tf
terraform -chdir=infrastructure/terraform/modules/container-apps validate
```
  </verify>
  <done>
- Variables added for rate limit configuration
- Output added for ingestion_proxy_fqdn
- Terraform validates successfully
  </done>
</task>

</tasks>

<verification>
Overall plan verification:

```bash
# Terraform validation
cd infrastructure/terraform/modules/container-apps
terraform init
terraform validate
terraform fmt -check

# Verify resource exists
grep -c 'resource "azurerm_container_app" "ingestion_proxy"' main.tf

# Verify critical configurations
grep -A 2 "min_replicas" main.tf | grep "= 1"
grep -A 2 "max_replicas" main.tf | grep "= 1"
grep "external_enabled" main.tf | grep "false"

# Verify health probes
grep -c "startup_probe" main.tf
grep -c "liveness_probe" main.tf
grep -c "readiness_probe" main.tf
```

Expected output:
- Terraform validation succeeds
- Single replica configuration confirmed
- Internal ingress confirmed
- All three health probes present
</verification>

<success_criteria>
1. azurerm_container_app.ingestion_proxy resource created
2. Single replica enforced (min/max = 1)
3. Internal ingress configured (external_enabled = false)
4. TCP health probes configured (startup, liveness, readiness)
5. ingestion_proxy_fqdn output added
6. Terraform validates successfully
</success_criteria>

<output>
After completion, create `.planning/phases/01-rate-limiting-separation/01-02-SUMMARY.md`
</output>
